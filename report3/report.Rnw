\documentclass{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[hidelinks]{hyperref}
\usepackage[all]{hypcap}

\title{Neural Networks Assignment 3 \\
    Learning by gradient descent}
\author{Xeryus Stokkel (s2332795)}

\begin{document}

\maketitle

\section{Introduction}
Gradient descent is an often used method for optimization problems. It
requires that there is a continuous error function that describes a kind of
$N$-dimensional error landscape. By following the gradient at the current
position in the landscape the method aims to find a (local) minimum. This is a
point where by slightly changing any of the parameters the error would go up.
This is a very effective way of finding an optimal set of parameters.

Gradient descend can also be applied to neural networks when its output is
continuous and the labels of the data set are also continuous. From this an
error function can be created by taking the quadratic deviation $e(\sigma,
\tau) = \frac{1}{2}(\sigma - \tau)^2$ where $\sigma \in \mathbb{R}$ is the
output of the network and $\tau \in \mathbb{R}$ is the label of the example.
This can be turned into the error function
\[ E = \frac{1}{P} \frac{1}{2} \sum_{\mu=1}^P (\sigma(\mathbf{\xi}^\mu) -
    \tau(\mathbf{\xi}^\mu))^2 \]
for a data set $\mathbb{D} = \{\mathbf{\xi}^\mu, \tau(\mathbf{\xi}^\mu)\}
_{\mu=1}^P$. Each $\mathbf{\xi}^\mu \in \mathbb{R}^N$ is an example that will
be presented to the neural network.

\section{Method}

To learn the error function $E$ a simple feed-forward neural network with real
valued output is constructed. To get a real valued output a a so called soft committee machine is used. Its output is
\[ \sigma(\mathbf{\xi}^\mu) = \tanh(\mathbf{w}_1 \cdot \mathbf{\xi}^\mu) +
    \tanh(\mathbf{w}_2 \cdot \mathbf{\xi}^\mu) \]
where $\mathbf{w}_1$ and $\mathbf{w}_2$ are the $N$-dimensional weight vectors
of the two hidden units respectively. Both weight vectors are initialized
with random components and are of unit length. These weight vectors will be
adapted to minimize the error function $E$ during the learning process.

During the learning step the network gets presented one randomly selected
example ($\mathbf{\xi}^\nu$) from the $P$ examples with equal probability.
Only the contribution of the example $\mathbf{\xi}^\nu$ is taken into account,
so during this training step the error is $e^\nu = \frac{1}{2} (\sigma(
\mathbf{\xi}^\nu) - \tau(\mathbf{\xi}^\nu))^2$. The gradient $\nabla_j$ with
respect to weight vector $\mathbf{w}_j$ can be derived as follows

\begin{align*}
    \frac{\partial e^\nu}{\partial \mathbf{w}_j} &= (\tanh(\mathbf{w}_j \cdot
        \mathbf{\xi}^\nu) - \tau(\mathbf{\xi}^\nu)) \tanh'(\mathbf{w}_j \cdot
        \mathbf{\xi}^\nu) \mathbf{\xi}^\nu\\
     &= (\tanh(\mathbf{w}_j \cdot \mathbf{\xi}^\nu) - \tau(\mathbf{\xi}^\nu))
     (1 - \tanh^2(\mathbf{w}_j \cdot \mathbf{\xi}^\nu)) \mathbf{\xi}^\nu \\
     \nabla_j &= (\tanh(\mathbf{w}_j \cdot \mathbf{\xi}^\nu) -
        \tau(\mathbf{\xi}^\nu))      (1 - \tanh^2(\mathbf{w}_j \cdot
        \mathbf{\xi}^\nu)) \mathbf{\xi}^\nu
\end{align*}
so each weight vector can be updated independently by
\[ \mathbf{w}_j \gets \mathbf{w}_j - \eta \nabla_j e^\nu \]
where $\eta$ is the learning rate. By doing this repeatedly for all
$\mathbf{\xi}^\nu$ that have been randomly picked the error $E$ will be
minimized by stochastic gradient descent.

The data set is constructed from the given data set as follows. The training set
consists of the first $P$ examples in the data set. The test set consists of
the next $Q$ examples of the supplied set. This ensures that there is no
overlap between the training and the test set so that the best results are
obtained.

One of the best measures of how well a neural network performs is to look at
how the error evolves over time. This indicates how fast the network is able to
learn the function. To test this the network is trained on a fixed subset of
the data. The first 2000 entries of the data set are used to train the network,
it is tested on the next 200 entries of the data set. $\eta = 0.05$ during this
experiment so that the error is not influenced by a dynamic learning rate. The
network is trained and evaluated 100 times to negate the effects of the initial
weights being random.

The learning rate is of influence of how fast the network converges to a
solution, setting it too low means that this will take a long time. However,
setting it too high also has a negative effect: the network might not converge
at all because it will overshoot the local minima. The effect of the magnitude
of the learning rate is also tested with the same parameters as above, but with
a varying learning rate.

Finally the size of the training set might also influence how well the neural
network is able to learn the function. Several different sizes of training set
are evaluated while the learning rate and the size of the test set is kept
constant.

\section{Results and discussion}

The results for the first experiment can be found in \autoref{fig:const_eta},
it shows both the error for the training set ($E$) and the error for the test
set $E_test$. It clearly shows that the network quickly minimizes the error at
the start, but around $t = 500$ the error functions level off into a plateau
state for the next 800 epochs. After that the errors slowly level off to their
final value of $\sim 0.02$.

From \autoref{fig:const_eta} it is also quite clear that the network does not
perform as well on the test set as on the training set. This indicates that the
network slightly overfits on the training set. This is not surprising since the
neural network has never seen any of the data points in the test set so it
cannot learn what the corresponding output should be. It can only respond with
the most likely output based on what it has learned from the training set,
which is the goal of training a neural network.

<<'const_eta', cache=T, echo=F, dev='tikz', fig.pos='t', fig.height=4, fig.cap='Error of the neural network during training. $E$ shows the error of the network on the training set while $E_\\text{test}$ shows the error on the test set. Note that the $y$-axis is logarithmic.'>>=
dat = read.csv('results.csv', header=T)
E = aggregate(cbind(E, E_test) ~ t, data=dat, FUN=mean)
E = E[ order(E$t),]

plot(E$t, E$E,
     type='l',
     xlab='Epoch',
     ylab='Error',
     col='blue',
     log='y')
lines(E$t, E$E_test,
      col='red')
legend('topright',
       c('$E$', '$E_\\text{test}$'),
       col=c('blue', 'red'),
       lty=1,
       inset=0.03)
@

<<'eta_sweep', cache=F, echo=F, dev='tikz', fig.pos='t', fig.height=4.5, fig.cap='Error on the test set for several different values of $\\eta$, the learning rate. The training and testing sets were both kept constant in size and which examples were in them.'>>=
dat = read.csv('eta_sweep.csv', header=T)
eta = aggregate(E_test ~ t + eta, data=dat, FUN=mean)

plot(eta$t[eta$eta==0.01], eta$E[eta$eta==0.01],
     type='l',
     xlab='Epoch',
     ylab='Error',
     col='blue',
     ylim=c(0, 0.3))
lines(eta$t[eta$eta==0.05], eta$E[eta$eta==0.05], col='red')
lines(eta$t[eta$eta==0.1], eta$E[eta$eta==0.1], col='green')
lines(eta$t[eta$eta==0.001], eta$E[eta$eta==0.001], col='black')
lines(eta$t[eta$eta==0.005], eta$E[eta$eta==0.005], col='cyan')
lines(eta$t[eta$eta==0.15], eta$E[eta$eta==0.15], col='purple')
legend('topright',
       c('0.001', '0.005', '0.01', '0.05', '0.1', '0.15'),
       col=c('black', 'cyan', 'blue', 'red', 'green', 'purple'),
       lty=1,
       inset=0.03,
       title='$\\eta$',
       bg='white')
@

The effects of various values of $\eta$, the learning rate, are shown in \autoref{fig:eta_sweep}. It shows that only when $\eta = 0.05$ that there is a plateau, all other values of $\eta$ do not show a plateau state. Interestingly enough when $\eta = 0.1$ there are two distinct knees in the graph, one around $t = 500$ and the other at $t = 3000$. This indicates that at some point learning does slow down. The most likely cause is that gradient descent works quite well for a part of the gradient, moving slowly to the minimum for those dimensions. Other parts of the gradient are not descended smoothly but quite jaggedly, the $w$ vectors jump across the minimum for some of the dimensions but the absolute distance to the minimum does decrease. This means that the network is able to learn from the data, but not as efficiently as when $\eta$ is smaller.

For $\eta = 0.15$ we can see that the error is on average \Sexpr{round(median(eta$E[eta$eta==0.15]), 3)} which is higher than for any of the other learning rates. It is likely that the solution of the neural network diverges from the actual solution. This also strengthens the conclusion about $\eta = 0.1$ because a neural network will shows oscillating behaviour when the learning rate is set too high for smooth convergence, and too low to show diverging behaviour.

The network shows smooth convergence when the learning rate is 0.001, 0.005, 0.01, or 0.05. When $\eta = 0.05$ the network reaches a plateau state as discussed above, other values of $\eta$ do not have this effect. When the learning rate is too low the network still converges but it does so very slowly as the graph for $\eta = 0.001$ shows. Although it is important to converge on the solution smoothly, doing so too slowly means that too much time will be spend training. Training can be sped up by taking a higher learning rate.

One of the most interesting curves is that of $\eta = 0.01$. It shows fast convergence on the solution, but after finding the optimal solution with an error of $\Sexpr{round(min(eta$E[eta$eta==0.01]), 3)}$ the error starts to increase again. This means that the network is overfitting on the training set and starts to loose its ability to generalize and perform well on the test set. The same also appears to happen when $\eta = 0.005$ although it happens slower and the overfitting effect is less pronounced as when $\eta = 0.01$. Although the effect is not as strong it might still be better to use a learning rate of 0.01 since it is easier to detect where the minimum error is because fewer training epochs are needed and the graph is not as `flat', so it is easier to determine after how many epoch the minimum has been reached.

<<'P_sweep', cache=T, echo=F, dev='tikz', fig.pos='t', fig.height=4, fig.cap='Performance of the neural network with varying size of the training set. The size of the test set was constant but the included examples depend on the size of the training set. Note that the $y$-axis is logarithmic.'>>=
dat = read.csv('train_sweep.csv', header=T)
E = aggregate(E_test ~ t + P, data=dat, FUN=mean)
plot(E$t[E$P==4000], E$E[E$P==4000],
     type='l',
     xlab='Epoch',
     ylab='Error',
     col='black',
     log='y')
lines(E$t[E$P==2000], E$E[E$P==2000], col='red')
lines(E$t[E$P==1500], E$E[E$P==1500], col='green3')
lines(E$t[E$P==1000], E$E[E$P==1000], col='blue')
lines(E$t[E$P==500], E$E[E$P==500], col='cyan')
lines(E$t[E$P==400], E$E[E$P==400], col='maroon')
lines(E$t[E$P==200], E$E[E$P==200], col='purple')
lines(E$t[E$P==100], E$E[E$P==100], col='gray')
lines(E$t[E$P==50], E$E[E$P==50], col='orange')
legend('topright',
       c('50', '100', '200', '400', '500', '1000', '1500', '2000', '4000'),
       col=c('orange', 'gray', 'purple', 'maroon', 'cyan', 'blue', 'green',
             'red', 'black'),
       lty=1,
       inset=0.03,
       title='$P$',
       bg='white')
@

\end{document}
